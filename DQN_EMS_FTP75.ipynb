{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a7f4baa4",
   "metadata": {},
   "source": [
    "# DQN-EMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "785c952e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import os \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\" #使用cpu\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '1'\n",
    "import tensorflow.compat.v1 as tf\n",
    "import numpy as np\n",
    "from EREV_model import EREV_model\n",
    "import scipy.io as scio\n",
    "import matplotlib.pyplot as plt\n",
    "from Priority_Replay import Memory, SumTree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bb50a46",
   "metadata": {},
   "source": [
    "## 超参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1978d100",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_EPISODES = 1               # 1500 运行次数\n",
    "memory_capacity = 10000         # 记忆容量\n",
    "batch_size = 64                 # 一次训练所抓取的数据样本数量\n",
    "learning_rate = 0.001           # 学习率：旧的Q值将从新的Q值哪里学到的新Q占自身的多少比重。\n",
    "                                # 值为0代理不会学到任何东西（旧信息是重要的），值为1新发现的信息是唯一重要的信息。\n",
    "reward_decay = 0.9              # 奖励递减未来奖励的重要性。\n",
    "                                # 值为0意味着只考虑短期奖励，其中1的值更重视长期奖励。\n",
    "e_greedy = 1                    # 贪心 利用概率ε来选择随机动作\n",
    "e_greedy_increment = 0.00001    # 贪心递减\n",
    "replace_target_iter = 300       # 每300步更新target参数\n",
    "np.random.seed(1)               # 如果使用相同的seed()值，则每次生成的随即数都相同\n",
    "tf.set_random_seed(1)\n",
    "tf.reset_default_graph()   # Python的控制台会保存上次运行结束的变量\n",
    "output_graph = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "597e3cf1",
   "metadata": {},
   "source": [
    "## DQN算法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c4956c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepQNetwork():\n",
    "    def __init__(self, a_dim, s_dim):\n",
    "        self.a_dim = a_dim                                   # 动作\n",
    "        self.s_dim = s_dim                                   # 状态\n",
    "        self.lr = learning_rate                              # 学习率\n",
    "        self.gamma = reward_decay                            # 奖励递减\n",
    "        self.epsilon_max = e_greedy                          # 贪心\n",
    "        self.epsilon_increment = e_greedy_increment          # 贪心递减\n",
    "        self.replace_target_iter = replace_target_iter       # 更新target\n",
    "        self.memory_size = memory_capacity                   # 记忆库容量\n",
    "        self.batch_size = batch_size\n",
    "        self.epsilon = 0 if e_greedy_increment is not None else self.epsilon_max # 更新epsilon贪心\n",
    "        self.learn_step_counter = 0                          # 记录学习次数\n",
    "        self.memory = Memory(capacity = memory_capacity)     # 存储记忆\n",
    "        self.ISWeights = tf.placeholder(tf.float32, [None, 1], 'ISWeights')\n",
    "        self._build_net()\n",
    "        self.t_params = tf.get_collection('target_net_params') # 列出目标网络的所有参数\n",
    "                                                               # f.get_collection:从一个集合中取出变量\n",
    "        self.e_params = tf.get_collection('eval_net_params')   # 列出评价网络的所有参数\n",
    "        self.replace_target_op = [tf.assign(t, e) for t, e in zip(self.t_params, self.e_params)]# 网络参数替换\n",
    "                                                               # tf.assign:将t的值变为e\n",
    "        self.sess = tf.Session()                               # Session 是 Tensorflow 为了控制,和输出文件的执行的语句\n",
    "        self.sess.run(tf.global_variables_initializer())       # 运行 session.run() 可以获得你要得知的运算结果\n",
    "        self.t_params = self.sess.run(self.t_params)           # 或者是你所要运算的部分.\n",
    "        self.e_params = self.sess.run(self.e_params)\n",
    "        self.cost_history = []                                 # 存储消耗\n",
    "\n",
    "    def _build_net(self):\n",
    "        ############################## 评价网络\n",
    "        # eval_net 四层，输入：s_dim(状态空间)；输出：a_dim(动作空间)\n",
    "        # tf.placeholder:在神经网络构建graph的时候在模型中的占位，此时并没有把要输入的数据传入模型，它只会分配必要的内存。\n",
    "        # 等建立session，在会话中，运行模型的时候通过feed_dict()函数向占位符喂入数据。\n",
    "        self.s = tf.placeholder(tf.float32, [None, self.s_dim], name = 's')\n",
    "        self.q_target = tf.placeholder(tf.float32, [None, self.a_dim], name = 'q_target')\n",
    "        # tf.variable_scope:在模型中开辟各自的空间，而其中的变量均在这个空间内进行管理\n",
    "        # with:上下文管理，需要事先做一些设置，事后做一些清理\n",
    "        with tf.variable_scope('eval_net'):\n",
    "            c_names, n_unit, w_initializer, b_initializer = \\\n",
    "            ['eval_net_params', tf.GraphKeys.GLOBAL_VARIABLES], 200,\\\n",
    "            tf.random_normal_initializer(0, 0.3), tf.constant_initializer(0.1)\n",
    "            # 返回一个生成具有正态分布的张量的初始化器\n",
    "            # tf.get_variable(名称name、变量规格shape、变量初始化方式initializer、所属集合collections。)\n",
    "            with tf.variable_scope('layer1'):\n",
    "                w1 = tf.get_variable('w1', [self.s_dim, n_unit], initializer = w_initializer, collections=c_names)\n",
    "                b1 = tf.get_variable('b1', [1, n_unit], initializer = b_initializer, collections = c_names)\n",
    "                layer1 = tf.nn.relu(tf.matmul(self.s, w1) + b1)\n",
    "                \n",
    "            with tf.variable_scope('layer2'):\n",
    "                w2 = tf.get_variable('w2', [200, 100], initializer = w_initializer, collections = c_names)\n",
    "                b2 = tf.get_variable('b2', [1, 100], initializer = b_initializer, collections = c_names)\n",
    "                layer2 = tf.nn.relu(tf.matmul(layer1, w2) + b2)    \n",
    "                \n",
    "            with tf.variable_scope('layer3'):\n",
    "                w3 = tf.get_variable('w3', [100, 50], initializer = w_initializer, collections = c_names)\n",
    "                b3 = tf.get_variable('b3', [1, 50], initializer = b_initializer, collections = c_names)\n",
    "                layer3 = tf.nn.relu(tf.matmul(layer2, w3) + b3)  \n",
    "                \n",
    "            with tf.variable_scope('layer4'):\n",
    "                w4 = tf.get_variable('w4', [50, self.a_dim], initializer = w_initializer, collections = c_names)\n",
    "                b4 = tf.get_variable('b4', [1, self.a_dim], initializer = b_initializer, collections = c_names)\n",
    "                self.q_eval = tf.matmul(layer3, w4) + b4\n",
    "        # tf.squared_difference:矩阵x，y按元素求（x-y）²\n",
    "        # tf.reduce_mean：计算平均值\n",
    "        with tf.variable_scope('loss'):\n",
    "            # 从重播缓冲区中抽取随机批次的转换，并用以下公式计算损失\n",
    "            self.loss = tf.reduce_mean(tf.squared_difference(self.q_target, self.q_eval)) * self.ISWeights\n",
    "        # 梯度下降算法\n",
    "        # 针对实际网络参数，执行梯度下降，以使损失最小化\n",
    "        with tf.variable_scope('train_op'):\n",
    "            self.train_op = tf.train.RMSPropOptimizer(self.lr).minimize(self.loss)\n",
    "        \n",
    "        ##############################  目标网络\n",
    "        self.s_ = tf.placeholder(tf.float32, [None, self.s_dim], name = 's_')\n",
    "        # target_net 四层，输入：s_dim(状态空间)；输出：a_dim(动作空间)\n",
    "        with tf.variable_scope('target_net'):\n",
    "            c_names, n_unit, w_initializer, b_initializer = \\\n",
    "            ['target_net_params', tf.GraphKeys.GLOBAL_VARIABLES], 200,\\\n",
    "            tf.random_normal_initializer(0, 0.3), tf.constant_initializer(0.1)\n",
    "            \n",
    "            with tf.variable_scope('layer1'):\n",
    "                w1 = tf.get_variable('w1', [self.s_dim, n_unit], initializer = w_initializer, collections = c_names)\n",
    "                b1 = tf.get_variable('b1', [1, n_unit], initializer = b_initializer, collections = c_names)\n",
    "                layer1 = tf.nn.relu(tf.matmul(self.s_, w1) + b1)\n",
    "                \n",
    "            with tf.variable_scope('layer2'):\n",
    "                w2 = tf.get_variable('w2', [200, 100], initializer = w_initializer, collections = c_names)\n",
    "                b2 = tf.get_variable('b2', [1, 100], initializer = b_initializer, collections = c_names)\n",
    "                layer2 = tf.nn.relu(tf.matmul(layer1, w2) + b2)\n",
    "                \n",
    "            with tf.variable_scope('layer3'):\n",
    "                w3 = tf.get_variable('w3', [100, 50], initializer = w_initializer, collections = c_names)\n",
    "                b3 = tf.get_variable('b3', [1, 50], initializer = b_initializer, collections = c_names)\n",
    "                layer3 = tf.nn.relu(tf.matmul(layer2, w3) + b3)\n",
    "            \n",
    "            with tf.variable_scope('layer4'):\n",
    "                w4 = tf.get_variable('w4', [50, self.a_dim], initializer = w_initializer, collections = c_names)\n",
    "                b4 = tf.get_variable('b4', [1, self.a_dim], initializer = b_initializer, collections = c_names)\n",
    "                self.q_next = tf.matmul(layer3, w4) + b4  \n",
    "       \n",
    "        with tf.Session() as sess:#运算结束后session自动关闭\n",
    "            sess.run(tf.global_variables_initializer())#执行运算\n",
    "            self.saver = tf.train.Saver(max_to_keep = MAX_EPISODES)\n",
    "            #保存模型，参数max_to_keep ，用来设置保存模型的个数，默认为5\n",
    "                        \n",
    "    def store_transition(self, s, a, r, s_):\n",
    "        if not hasattr(self, 'memory_counter'):\n",
    "            self.memory_counter = 0\n",
    "        # 沿着水平方向将数组堆叠起来\n",
    "        transition = np.hstack((s, a, r, s_))\n",
    "\n",
    "        self.memory.store(transition)            \n",
    "        self.memory_counter += 1\n",
    "            \n",
    "    def choose_action(self, observation):\n",
    "        observation = observation[np.newaxis, :]\n",
    "        # np.newaxis:选取部分的数据增加一个维度\n",
    "        if np.random.uniform() < self.epsilon:\n",
    "            action_value = self.sess.run(self.q_eval, feed_dict = {self.s: observation})\n",
    "            action = np.argmax(action_value)            \n",
    "        else:\n",
    "            action = np.random.randint(0, self.a_dim)\n",
    "                \n",
    "        return action\n",
    "        \n",
    "    def learn(self):\n",
    "        # 更新神经网络参数\n",
    "        # 每隔k步之后，拷贝实际网络权重到目标网络权重中\n",
    "        if self.learn_step_counter % self.replace_target_iter == 0:\n",
    "            self.sess.run(self.replace_target_op)\n",
    "            \n",
    "        tree_index, batch_memory, ISWeights = self.memory.sample(batch_size)\n",
    "            \n",
    "        q_eval, q_next = self.sess.run([self.q_eval, self.q_next], feed_dict = {self.s: batch_memory[:, :self.s_dim], self.s_: batch_memory[:, -self.s_dim:]})\n",
    "        q_target = q_eval.copy()\n",
    "        \n",
    "        batch_index = np.arange(self.batch_size, dtype = np.int32)\n",
    "        eval_act_index = batch_memory[:, self.s_dim].astype(int)\n",
    "        reward = batch_memory[:, self.s_dim + 1]\n",
    "\n",
    "        q_target[batch_index, eval_act_index] = reward + self.gamma * np.max(q_next, axis = 1)\n",
    "\n",
    "        abs_td_error = np.abs(q_target[batch_index, eval_act_index] - q_eval[batch_index, eval_act_index]) * np.array(ISWeights).flatten()        \n",
    "        self.memory.batch_update(tree_index, abs_td_error)\n",
    "            \n",
    "        _, self.cost = self.sess.run([self.train_op, self.loss], feed_dict = {self.s: batch_memory[:, :self.s_dim], self.q_target: q_target, self.ISWeights: ISWeights})\n",
    "        self.cost_history.append(self.cost)\n",
    "        self.epsilon = self.epsilon + self.epsilon_increment if self.epsilon < self.epsilon_max else self.epsilon_max\n",
    "        exploration = self.epsilon        \n",
    "        self.learn_step_counter += 1\n",
    "\n",
    "        return exploration\n",
    "\n",
    "    def savemodel(self):\n",
    "        self.saver.save(self.sess, 'save\\save_net.ckpt', global_step = step_episode)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44066c64",
   "metadata": {},
   "source": [
    "## 运行参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "644b8a23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From B:\\Anaconda\\Anaconda3\\envs\\TF1.15\\lib\\site-packages\\tensorflow_core\\python\\training\\rmsprop.py:119: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "s_dim = 3                                                    # 状态\n",
    "a_dim = 14                                                   # 动作\n",
    "DQN = DeepQNetwork(a_dim, s_dim)                             # 输入动作与状态参数\n",
    "data_path = 'Data_Standard Driving Cycles/Standard_NEDC.mat' # 驾驶循环\n",
    "data = scio.loadmat(data_path)                               # 驾驶循环数据\n",
    "car_spd_one = data['speed_vector']                           # 每秒速度  m/s\n",
    "total_milage = np.sum(car_spd_one) / 1000                    # 总行驶里程\n",
    "exploration = 1\n",
    "total_step = 0                                               # 累计步数\n",
    "step_episode = 0                                             # 步数\n",
    "mean_reward = 0                                              # 平均奖励\n",
    "mean_reward_all = 0                                          # 总平均奖励\n",
    "cost_Engine_list = []                                        # 燃油消耗\n",
    "cost_all_list = []                                           # 奖励和等效燃油总消耗\n",
    "cost_Engine_100Km_list = []                                  # 每百公里总消耗\n",
    "mean_reward_list = []                                        # 平均奖励\n",
    "list_even = []\n",
    "list_odd = []\n",
    "mean_discrepancy_list = []\n",
    "SOC_final_list = []                                          # 最终SOC\n",
    "EREV = EREV_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23bd6d65",
   "metadata": {},
   "source": [
    "## 循环"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "34fa3d8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "循环次数: 0 燃油消耗: 347.826 g 燃油消耗: 0.834 L 百公里燃油消耗: 7.631 L/100km 最终SOC: 0.533 Explore: 1.000\n",
      "WARNING:tensorflow:From B:\\Anaconda\\Anaconda3\\envs\\TF1.15\\lib\\site-packages\\tensorflow_core\\python\\training\\saver.py:963: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to delete files with this prefix.\n"
     ]
    }
   ],
   "source": [
    "for i in range(MAX_EPISODES):\n",
    "    ep_reward = 0         # 每步奖励\n",
    "    ep_reward_all = 0     # 循环奖励和\n",
    "    a = 0                 # 动作\n",
    "    step_episode += 1     # 每步加一\n",
    "    Reward_list = []      # 奖励\n",
    "    Reward_list_all = []  # 循环奖励\n",
    "    # 发动机\n",
    "    Eng_spd_list = []     # 发动机转速\n",
    "    Eng_trq_list = []     # 发动机转矩\n",
    "    Eng_pwr_list = []     # 发动机功率\n",
    "    Eng_eta_list = []     # 发动机效率\n",
    "    Eng_pwr_opt_list = [] # 发动机工作点\n",
    "    # 发电机\n",
    "    Gen_spd_list = []     # 发电机转速\n",
    "    Gen_trq_list = []     # 发电机转矩\n",
    "    Gen_pwr_list = []     # 发电机功率\n",
    "    Gen_eta_list = []     # 发电机效率\n",
    "    # 驱动电机\n",
    "    Mot_spd_list = []     # 驱动电机转速\n",
    "    Mot_trq_list = []     # 驱动电机转矩\n",
    "    Mot_pwr_list = []     # 驱动电机功率\n",
    "    Mot_eta_list = []     # 驱动电机效率\n",
    "    # 电池\n",
    "    Batt_pwr_list = []    # 电池输出功率\n",
    "    inf_batt_list = []    # 超出电流限制\n",
    "    inf_batt_one_list = []# 超出功率限制\n",
    "    # 整车\n",
    "    SOC = 0.65            # 初始SOC\n",
    "    SOC_origin = SOC      # 初始SOC\n",
    "    SOC_data = []         # soc\n",
    "    P_req_list = []       # 轮胎驱动需求功率\n",
    "    P_out_list = []       # 电池+增程器=输出功率\n",
    "    T = 0                 # 驱动、制动转矩\n",
    "    T_new = 0             # 驱动、制动转矩更新状态\n",
    "    T_list = []           # 驱动、制动转矩列表\n",
    "    car_spd = car_spd_one[:, 0]   # 车速\n",
    "    car_a = car_spd_one[:, 0] - 0 # 加速度\n",
    "    car_a_list = []                         # 加速度列表\n",
    "    # 车辆初始状态\n",
    "    s = np.zeros(s_dim)     # 车辆状态\n",
    "    s[0] = car_spd / 33.4   # 车速 / 最大车速\n",
    "    s[1] = T / 2000         # 将加速度改为驱动和制动转矩   (car_a - (-1.5)) / (1.5- (-1.5))\n",
    "    s[2] = SOC              # SOC\n",
    "    # 驾驶工况循环   1-1219\n",
    "    for j in range(car_spd_one.shape[1] - 1):\n",
    "        # 动作对应的发动机功率\n",
    "        action = DQN.choose_action(s)\n",
    "        if action == 0:\n",
    "            a += 0\n",
    "        if action == 1:\n",
    "            a += (  1 / 105)\n",
    "        if action == 2:\n",
    "            a += ( -1 / 105)\n",
    "        if action == 3:\n",
    "            a += (  2 / 105)\n",
    "        if action == 4:\n",
    "            a += ( -2 / 105)\n",
    "        if action == 5:\n",
    "            a += (  4 / 105)\n",
    "        if action == 6:\n",
    "            a += ( -4 / 105)\n",
    "        if action == 7:\n",
    "            a += (  6 / 105)\n",
    "        if action == 8:\n",
    "            a += ( -6 / 105)\n",
    "        if action == 9:\n",
    "            a += (  8 / 105)\n",
    "        if action == 10:\n",
    "            a += ( -8 / 105)\n",
    "        if action == 11:\n",
    "            a += ( 10 / 105)\n",
    "        if action == 12:\n",
    "            a += (-10 / 105)\n",
    "        if action == 13:\n",
    "            a = 0\n",
    "        Eng_pwr_opt = a * 105000\n",
    "        # 运行增程式电动汽车模型   这里是car_a，不能改为T\n",
    "        out, cost, I = EREV.run(car_spd, car_a, Eng_pwr_opt, SOC)\n",
    "        P_req_list.append(float(out['P_req']))              # 轮胎驱动需求功率\n",
    "        P_out_list.append(float(out['P_out']))              # 电池+增程器=输出功率\n",
    "        # 发动机\n",
    "        Eng_spd_list.append(float(out['Eng_spd']))          # 发动机转速\n",
    "        Eng_trq_list.append(float(out['Eng_trq']))          # 发动机转矩\n",
    "        Eng_pwr_list.append(float(out['Eng_pwr']))          # 发动机功率\n",
    "        Eng_pwr_opt_list.append(float(out['Eng_pwr_opt']))  # 发动机工作点\n",
    "        Eng_eta_list.append(float(out['Mot_eta']))          # 发动机效率\n",
    "        # 发电机\n",
    "        Gen_spd_list.append(float(out['Gen_spd']))          # 发电机转速\n",
    "        Gen_trq_list.append(float(out['Gen_trq']))          # 发电机转矩\n",
    "        Gen_pwr_list.append(float(out['Gen_pwr']))          # 发电机功率\n",
    "        Gen_eta_list.append(float(out['Gen_eta']))          # 发电机效率\n",
    "        # 驱动电机\n",
    "        Mot_spd_list.append(float(out['Mot_spd']))          # 驱动电机转速\n",
    "        Mot_trq_list.append(float(out['Mot_trq']))          # 驱动电机转矩\n",
    "        Mot_pwr_list.append(float(out['Mot_pwr']))          # 驱动电机功率\n",
    "        Mot_eta_list.append(float(out['Mot_eta']))          # 驱动电机效率\n",
    "        # 电池\n",
    "        Batt_pwr_list.append(float(out['Batt_pwr']))        # 电池功率\n",
    "        inf_batt_list.append(int(out['inf_batt']))          # 超出电流限制\n",
    "        inf_batt_one_list.append(int(out['inf_batt_one']))  # 超出功率限制\n",
    "        SOC_new = float(out['SOC'])                         # SOC变化\n",
    "        SOC_data.append(SOC_new)                            # SOC列表\n",
    "        # 驱动、制动转矩\n",
    "        T_new = float(out['T'])                             # 驱动和制动转矩\n",
    "        T_list.append(float(out['T']))                      # 转矩列表\n",
    "        # 增程器消耗燃油  g\n",
    "        cost = float(cost)\n",
    "        # SOC (< 0.45 and >0.85) 燃油奖励 = cost(燃油)\n",
    "        r = - cost              # 燃油奖励     <0\n",
    "        ep_reward += r          # 燃油奖励和   <0\n",
    "        Reward_list.append(r)   # 燃油奖励列表 <0\n",
    "        # SOC (0.45～0.85)       奖励 = -(α|ΔSOC|^2 + βfuel)\n",
    "        if SOC_new < 0.4 or SOC_new > 0.8:\n",
    "            r = - ((350 * ((0.6 - SOC_new) ** 2)) + cost)\n",
    "        # 下一步车辆状态\n",
    "        car_spd = car_spd_one[:, j + 1]                      # 下一步车速\n",
    "        car_a = car_spd_one[:, j + 1] - car_spd_one[:, j]    # 下一步加速度\n",
    "        car_a_list.append(car_a)                   # 加速度列表\n",
    "        s_ = np.zeros(s_dim)\n",
    "        s_[0] = car_spd / 33.4\n",
    "        s_[1] = T_new / 2000  # 加速度改为转矩 (car_a - (-1.5)) / (1.5- (-1.5))\n",
    "        s_[2] = SOC_new\n",
    "        DQN.store_transition(s, action, r, s_)      # 经验池\n",
    "        if total_step > 10000 and (total_step % 5 == 0):\n",
    "            exploration = DQN.learn()\n",
    "        # 状态交换\n",
    "        s = s_\n",
    "        ep_reward_all += r           # 奖励和 -(α|ΔSOC|^2 + βfuel)  <0\n",
    "        Reward_list_all.append(r)    # 循环奖励\n",
    "        total_step += 1              # 步数加一\n",
    "        SOC = SOC_new                # SOC更新\n",
    "        T = T_new                    # 转矩更新\n",
    "        # 完成每次循环工况输出\n",
    "        if j == (car_spd_one.shape[1] - 2):  # j = 1218\n",
    "            SOC_final_list.append(SOC)\n",
    "            mean_reward = - ep_reward_all / car_spd_one.shape[1]  # 平均每秒奖励\n",
    "            mean_reward_list.append(mean_reward)                  # 平均每秒奖励\n",
    "            # 燃油消耗  L\n",
    "            cost_Engine = - (ep_reward / 0.725 / 1000)   # 增程器燃油总消耗   L cost_Engine = - (cost / 0.725 / 1000)\n",
    "            cost_all = - (ep_reward_all / 0.725 / 1000)  # 奖励和等效燃油消耗 L (-(α|ΔSOC|^2 + βfuel)) / 0.725 / 1000)\n",
    "            # 燃油总消耗(cost_Engine) = 每次循环消耗的电量转变为燃油 + 增程器燃油总消耗\n",
    "            cost_Engine += (SOC < SOC_origin) * (SOC_origin - SOC) * (350 * 75) * 3600 / 43070 / 0.725 / 1000\n",
    "            cost_Engine_list.append(cost_Engine)\n",
    "            # 百公里燃油消耗(cost_Engine_100Km_list) = 燃油总消耗(cost_Engine) / 总行驶里程(total_milage)\n",
    "            cost_Engine_100Km_list.append(cost_Engine * (100 / total_milage))\n",
    "            # 奖励和等效燃油消耗(cost_all) =  (-(α|ΔSOC|^2 + βfuel)) / 0.725 / 1000) + 每次循环消耗的电量转变为燃油\n",
    "            cost_all += (SOC < SOC_origin) * (SOC_origin - SOC) * (350 * 75) * 3600 / 43070 / 0.725 / 1000\n",
    "            cost_all_list.append(cost_all)\n",
    "\n",
    "            print('循环次数:',i, '燃油消耗: %.3f g' % -ep_reward,'燃油消耗: %.3f L' % cost_Engine, '百公里燃油消耗: %.3f L/100km' % (cost_Engine * (100 / total_milage)), '最终SOC: %.3f' % SOC_new, 'Explore: %.3f' % exploration,)\n",
    "            Reward_final = []\n",
    "            Reward_final.append(ep_reward)\n",
    "    # 平均每秒奖励和\n",
    "    mean_reward_all += mean_reward   \n",
    "    if (step_episode % 10) == 0 and step_episode >= 10:\n",
    "        if (step_episode / 10) % 2 == 0:\n",
    "            list_even.append(mean_reward_all)\n",
    "        else:\n",
    "            list_odd.append(mean_reward_all)\n",
    "        mean_reward_all = 0 \n",
    "    # 保存模型\n",
    "    DQN.savemodel()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88b347a9",
   "metadata": {},
   "source": [
    "## 结果处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c1b77696",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_discrepancy_list = list(map(lambda x, y: y - x, list_even, list_odd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a83014df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEGCAYAAAB/+QKOAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90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\nSQoIERFp0v8HYCWbk9zYrjQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## SOC\n",
    "x = np.arange(0, len(SOC_data), 1)\n",
    "y = SOC_data\n",
    "plt.plot(x, y)\n",
    "plt.xlabel('time')\n",
    "plt.ylabel('SOC')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a9f42924",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.04166667])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(car_a_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dec22b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:TF1.15]",
   "language": "python",
   "name": "conda-env-TF1.15-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
